dataset: hans
templates:
  1b2386f7-4b2b-436b-a0cc-7092a90964f7: !Template
    answer_choices:
    - 'Yes'
    - 'No'
    id: 1b2386f7-4b2b-436b-a0cc-7092a90964f7
    jinja: '{{premise}} Does the previous passage support the claim that {{hypothesis}}?
      ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: false
      choices_in_prompt: false
      metric: null
      original_task: true
      task_format: Classification
    name: "\u2026does the previous passage support the claim that"
    reference: ''
  213f6f71-0987-4cba-8e16-85ed08b6d237: !Template
    answer_choices:
    - 'Yes'
    - 'No'
    id: 213f6f71-0987-4cba-8e16-85ed08b6d237
    jinja: Suppose {{premise}} Can we infer that {{hypothesis}}? ||| {{ answer_choices[label]
      }}
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: false
      choices_in_prompt: false
      metric: null
      original_task: true
      task_format: Classification
    name: "Suppose\u2026 Can we infer that\u2026"
    reference: ''
  930dbf9e-be95-458c-bf63-0358e36b8f8f: !Template
    answer_choices:
    - 'Yes'
    - 'No'
    id: 930dbf9e-be95-458c-bf63-0358e36b8f8f
    jinja: 'Sentence 1: {{premise}}

      Sentence 2: {{hypothesis}}

      Question: Does Sentence 1 entail Sentence 2? Yes or no? |||

      {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: false
      choices_in_prompt: true
      metric: null
      original_task: true
      task_format: Classification
    name: does S1 entail S2?
    reference: Adapted from Victor's prompts for XNLI.
  9666d06a-63eb-4992-a1f5-3e582ffe39a6: !Template
    answer_choices:
    - 'Yes'
    - 'No'
    id: 9666d06a-63eb-4992-a1f5-3e582ffe39a6
    jinja: Given that {{premise}} Does it follow that {{hypothesis}} Yes or no? |||
      {{ answer_choices[label] }}
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: false
      choices_in_prompt: true
      metric: null
      original_task: true
      task_format: Classification
    name: "given\u2026 does it follow that\u2026 "
    reference: ''
  9be63780-a784-4a8e-9440-4453c14f8a0e: !Template
    answer_choices:
    - 'True'
    - 'False'
    id: 9be63780-a784-4a8e-9440-4453c14f8a0e
    jinja: '{{premise}}

      Question: {{hypothesis}} True or False? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: false
      choices_in_prompt: true
      metric: null
      original_task: true
      task_format: Classification
    name: GPT-3 style
    reference: Same as reported in Figure G31 of the GPT-3 paper, although I'm not
      sure about phrasing the not_entailment label (could be either neutral and contradiction)
      simply as "False".
  b7676330-5e75-4f3d-96bd-2ab7aa10fbcd: !Template
    answer_choices:
    - 'Yes'
    - 'No'
    id: b7676330-5e75-4f3d-96bd-2ab7aa10fbcd
    jinja: '{{premise}} Based on the previous passage, is it true that {{hypothesis}}?
      ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: false
      choices_in_prompt: false
      metric: null
      original_task: true
      task_format: Classification
    name: based on the previous passage
    reference: "Adapted from the BoolQ prompts in Schick & Sch\xFCtze 2021."
