dataset: trec
templates:
  21d04668-c5b3-4418-bbb6-663f1ffdb97c: !Template
    answer_choices: Abbreviation ||| Entity ||| Description ||| Person ||| Location
      ||| Quantity
    id: 21d04668-c5b3-4418-bbb6-663f1ffdb97c
    jinja: "Categories: {{', '.join(answer_choices)}}\n\nWhat category best describes:\
      \ {{text}} \nAnswer: ||| {{ answer_choices [coarse_label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: what_category_best_describe
    reference: ''
  2d4e0add-cfca-4f54-80a2-ddd8e91f9fd6: !Template
    answer_choices: city ||| country ||| mountain ||| other location ||| state
    id: 2d4e0add-cfca-4f54-80a2-ddd8e91f9fd6
    jinja: '{% if coarse_label == 4 %}

      Is this question asking for {{'', ''.join(answer_choices)}}?

      {{text}}

      |||

      {{ answer_choices [fine_label-32] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_LOC
    reference: Fine grained labels with coarse-label `LOC`, context after question
  309bf243-2185-4090-ac66-a24f44d89966: !Template
    answer_choices: code ||| count ||| date ||| distance ||| price ||| order ||| other
      number ||| period of time ||| percentage ||| speed ||| temperature ||| size
      ||| weight
    id: 309bf243-2185-4090-ac66-a24f44d89966
    jinja: '{% if coarse_label == 5 %}

      {{text}}


      Is this question asking for {{'', ''.join(answer_choices)}}?

      |||

      {{ answer_choices [fine_label-37] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_NUM_context_first
    reference: Fine grained labels with coarse-label `NUM`, context provided first
  3aff84f3-e478-4598-abe8-40aa24cec1fa: !Template
    answer_choices: an animal ||| an organ of the body ||| a color ||| creative piece
      ||| currency ||| disease or medicine ||| event ||| food ||| musical instrument
      ||| language ||| letter ||| other entity ||| plant ||| product ||| religion
      ||| sport ||| substance ||| symbol ||| technique ||| term ||| vehicle ||| word
    id: 3aff84f3-e478-4598-abe8-40aa24cec1fa
    jinja: '{% if coarse_label == 1 %}

      Is this question asking for {{'', ''.join(answer_choices)}}?

      {{text}}

      |||

      {{ answer_choices [fine_label-2] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_ENTY
    reference: Fine grained labels with coarse-label `ENTY`, context after question
  43a188a2-b6dd-46a7-af2e-81a64b90b92a: !Template
    answer_choices: code ||| count ||| date ||| distance ||| price ||| order ||| other
      number ||| period of time ||| percentage ||| speed ||| temperature ||| size
      ||| weight
    id: 43a188a2-b6dd-46a7-af2e-81a64b90b92a
    jinja: '{% if coarse_label == 5 %}

      Is this question asking for {{'', ''.join(answer_choices)}}?

      {{text}}

      |||

      {{ answer_choices [fine_label-37] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_NUM
    reference: Fine grained labels with coarse-label `NUM`
  6c391f4f-027b-4425-88de-1dbb6aa706ee: !Template
    answer_choices: Abbreviation ||| Entity ||| Description ||| Person ||| Location
      ||| Quantity
    id: 6c391f4f-027b-4425-88de-1dbb6aa706ee
    jinja: 'Question: {{text}}


      Descriptors: {{'', ''.join(answer_choices)}}


      Best Descriptor?

      |||

      {{answer_choices[coarse_label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: pick_the_best_descriptor
    reference: ''
  71090d59-dd02-4cbd-8032-ad86179b9bd4: !Template
    answer_choices: abbreviation ||| expression abbreviated ||| an animal ||| an organ
      of the body ||| a color ||| creative piece ||| currency ||| disease or medicine
      ||| event ||| food ||| musical instrument ||| language ||| letter ||| other
      entity ||| plant ||| product ||| religion ||| sport ||| substance ||| symbol
      ||| technique ||| term ||| vehicle ||| word ||| definition ||| description |||
      manner of action ||| reason ||| group ||| individual ||| title ||| description
      ||| city ||| country ||| mountain ||| other location ||| state ||| code |||
      count ||| date ||| distance ||| price ||| order ||| other number ||| period
      of time ||| percentage ||| speed ||| temperature ||| size ||| weight
    id: 71090d59-dd02-4cbd-8032-ad86179b9bd4
    jinja: '{{text}}


      What is this question asking for?

      |||

      {{answer_choices[fine_label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: fine_grained_open_context_first
    reference: Fine grained classes without providing choices, context first.
  736b2629-ed57-48ce-a458-4cbc435c499b: !Template
    answer_choices: city ||| country ||| mountain ||| other location ||| state
    id: 736b2629-ed57-48ce-a458-4cbc435c499b
    jinja: '{% if coarse_label == 4 %}

      {{text}}


      Is this question asking for {{'', ''.join(answer_choices)}}?

      |||

      {{ answer_choices [fine_label-32] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_LOC_context_first
    reference: Fine grained labels with coarse-label `LOC`, context provided first
  7a3ed4dd-af89-493c-8efb-c67622f63034: !Template
    answer_choices: Abbreviation ||| Entity ||| Description ||| Person ||| Location
      ||| Quantity
    id: 7a3ed4dd-af89-493c-8efb-c67622f63034
    jinja: "Which category best describes the following question: {{text}} \n\nChoose\
      \ from the following list: \n{{', '.join(answer_choices)}}\n ||| {{ answer_choices\
      \ [coarse_label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: which_category_best_describes
    reference: ''
  7a9e6f3c-1dee-45b0-a315-1badaf59a7b8: !Template
    answer_choices: definition ||| description ||| manner of action ||| reason
    id: 7a9e6f3c-1dee-45b0-a315-1badaf59a7b8
    jinja: '{% if coarse_label == 2 %}

      Is this question asking for {{'', ''.join(answer_choices)}}?

      {{text}}

      |||

      {{ answer_choices[fine_label-24] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_DESC
    reference: Fine grained labels with coarse-label `DESC`, context after question
  861d1a48-1113-4f35-b777-2b2f12ab9d5d: !Template
    answer_choices: Abbreviation ||| Entity ||| Description ||| Person ||| Location
      ||| Quantity
    id: 861d1a48-1113-4f35-b777-2b2f12ab9d5d
    jinja: '{{text}}


      Is this asking about {{('', '').join(answer_choices)}}?

      |||

      {{ answer_choices [coarse_label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: trec1
    reference: Context then prompt
  93a06e72-2c15-4f8a-a46c-6a10919c4ea4: !Template
    answer_choices: abbreviation ||| expression abbreviated
    id: 93a06e72-2c15-4f8a-a46c-6a10919c4ea4
    jinja: '{% if coarse_label == 0 %}

      Is this question asking for an {{'', ''.join(answer_choices)}}?

      {{text}}

      |||

      {{answer_choices[fine_label] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_ABBR
    reference: Fine grained labels with coarse-label `ABBR`, context after question
  a0096044-3b4c-4c80-b139-25eac8fe692a: !Template
    answer_choices: abbreviation ||| expression abbreviated
    id: a0096044-3b4c-4c80-b139-25eac8fe692a
    jinja: '{% if coarse_label == 0 %}

      {{text}}

      Is this question asking for an {{'', ''.join(answer_choices)}}?

      |||

      {{answer_choices[fine_label] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_ABBR_context_first
    reference: Fine grained labels with coarse-label `ABBR`, context provided first
  aad2def1-b694-40ee-9c26-3d1cf5c577da: !Template
    answer_choices: Abbreviation ||| Entity ||| Description ||| Person ||| Location
      ||| Quantity
    id: aad2def1-b694-40ee-9c26-3d1cf5c577da
    jinja: 'Is the following question asking about {{'', ''.join(answer_choices)}}?


      {{text}}

      |||

      {{ answer_choices [coarse_label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: trec2
    reference: Prompt then context
  bc58ba18-24a5-4553-be0a-2dba60efdad6: !Template
    answer_choices: group ||| individual ||| title ||| description
    id: bc58ba18-24a5-4553-be0a-2dba60efdad6
    jinja: '{% if coarse_label == 3 %}

      Is this question asking for {{'', ''.join(answer_choices)}}?

      {{text}}

      |||

      {{ answer_choices[fine_label-28] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_HUM
    reference: Fine grained labels with coarse-label `HUM`, context after question
  cfa8fde0-8320-4050-8d6e-7619ab14adea: !Template
    answer_choices: abbreviation ||| expression abbreviated ||| an animal ||| an organ
      of the body ||| a color ||| creative piece ||| currency ||| disease or medicine
      ||| event ||| food ||| musical instrument ||| language ||| letter ||| other
      entity ||| plant ||| product ||| religion ||| sport ||| substance ||| symbol
      ||| technique ||| term ||| vehicle ||| word ||| definition ||| description |||
      manner of action ||| reason ||| group ||| individual ||| title ||| description
      ||| city ||| country ||| mountain ||| other location ||| state ||| code |||
      count ||| date ||| distance ||| price ||| order ||| other number ||| period
      of time ||| percentage ||| speed ||| temperature ||| size ||| weight
    id: cfa8fde0-8320-4050-8d6e-7619ab14adea
    jinja: 'What is this question asking for?


      {{text}}

      |||

      {{ answer_choices[fine_label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: fine_grained_open
    reference: Fine grained classes without providing choices.
  e98b9294-76b4-4172-a78c-9c6e5fdfe73b: !Template
    answer_choices: group ||| individual ||| title ||| description
    id: e98b9294-76b4-4172-a78c-9c6e5fdfe73b
    jinja: '{% if coarse_label == 3 %}

      {{text}}


      Is this question asking for {{'', ''.join(answer_choices)}}?

      |||

      {{ answer_choices [fine_label-28] }}{% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_HUM_context_first
    reference: Fine grained labels with coarse-label `HUM`, context provided first
  fa588c55-5c69-4fd0-a0b1-edbfa092f710: !Template
    answer_choices: definition ||| description ||| manner of action ||| reason
    id: fa588c55-5c69-4fd0-a0b1-edbfa092f710
    jinja: '{% if coarse_label == 2 %}

      {{text}}


      Is this question asking for {{'', ''.join(answer_choices)}}?

      |||

      {{ answer_choices [fine_label-24] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_DESC_context_first
    reference: Fine grained labels with coarse-label `DESC`, context provided first
