dataset: wmt15
subset: fr-en
templates:
  048ebbe2-fc1e-492b-a9be-9ea04cd98ef0: !Template
    answer_choices: null
    id: 048ebbe2-fc1e-492b-a9be-9ea04cd98ef0
    jinja: 'What is the English translation of : {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-fr-en-target
    reference: GPT-3 paper
  084baa02-db47-4d16-941a-ddcc351cd836: !Template
    answer_choices: null
    id: 084baa02-db47-4d16-941a-ddcc351cd836
    jinja: 'Given the following source text in English: {{translation["en"]}} , a
      good French translation is:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-en-fr-source+target
    reference: ''
  099ffec8-8348-4a86-90a9-5095e19b87cf: !Template
    answer_choices: null
    id: 099ffec8-8348-4a86-90a9-5095e19b87cf
    jinja: 'Translate this from French into English: {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-fr-en-source+target
    reference: https://arxiv.org/pdf/1910.10683.pdf
  0e3b43b4-16af-4f03-b9c1-ad6bfd0e243b: !Template
    answer_choices: null
    id: 0e3b43b4-16af-4f03-b9c1-ad6bfd0e243b
    jinja: 'Translate this from English into French: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-en-fr-source+starget
    reference: ''
  13acc84f-1bcb-442d-b96a-d087eb7d45a0: !Template
    answer_choices: null
    id: 13acc84f-1bcb-442d-b96a-d087eb7d45a0
    jinja: 'How do you say {{translation["en"]}} in French?

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: how_to_say-en-fr-target
    reference: ''
  3a6fd6dc-61a9-4c7c-acc8-57099cc3aea9: !Template
    answer_choices: null
    id: 3a6fd6dc-61a9-4c7c-acc8-57099cc3aea9
    jinja: 'English:  {{translation["en"]}}  translates into French as:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_en-fr-source+target
    reference: ''
  3c7f2aa6-63b1-4ecf-b493-a81c3e56e739: !Template
    answer_choices: null
    id: 3c7f2aa6-63b1-4ecf-b493-a81c3e56e739
    jinja: '{{translation["fr"]}}  translates into English as:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_fr-en-target
    reference: ''
  443e9acf-50df-43f4-9943-f8bdcca3bdef: !Template
    answer_choices: null
    id: 443e9acf-50df-43f4-9943-f8bdcca3bdef
    jinja: 'What is the English translation of the French  sentence: {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-fr-en-source+target
    reference: GPT-3 paper
  4ce9b78d-ed60-45cc-8125-242a2b3c5bf4: !Template
    answer_choices: null
    id: 4ce9b78d-ed60-45cc-8125-242a2b3c5bf4
    jinja: 'Translate this into English: {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-fr-en-target
    reference: ''
  6b5bd444-941c-4a16-9094-9610ca459312: !Template
    answer_choices: null
    id: 6b5bd444-941c-4a16-9094-9610ca459312
    jinja: 'Translate this into French: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-en-fr-target
    reference: ''
  6d7d61fd-cd2c-446e-a0ff-62b964d0355f: !Template
    answer_choices: null
    id: 6d7d61fd-cd2c-446e-a0ff-62b964d0355f
    jinja: 'French:  {{translation["fr"]}}  translates into English as:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_fr-en-source+target
    reference: ''
  77c63fad-d820-4d4e-95ce-1497a6176499: !Template
    answer_choices: null
    id: 77c63fad-d820-4d4e-95ce-1497a6176499
    jinja: 'If the French version says: {{translation["fr"]}}; then the English version
      should say:

      |||   {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-fr-en-source+target
    reference: ''
  7955fc1f-6171-483f-accc-d840df1397df: !Template
    answer_choices: null
    id: 7955fc1f-6171-483f-accc-d840df1397df
    jinja: 'What is the French translation of: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-en-fr-target
    reference: GPT-3 paper
  7a84aa1f-eca4-4b85-b3f3-ea46a7c89915: !Template
    answer_choices: null
    id: 7a84aa1f-eca4-4b85-b3f3-ea46a7c89915
    jinja: 'If the English version says: {{translation["en"]}}; then the French version
      should say:

      |||   {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-en-fr-source+target
    reference: ''
  927490ac-1935-4525-8145-17b8bfcdabe1: !Template
    answer_choices: null
    id: 927490ac-1935-4525-8145-17b8bfcdabe1
    jinja: 'If the original version says: {{translation["en"]}}; then the French version
      should say:

      |||   {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-en-fr-target
    reference: ''
  c05b6121-4f46-4088-a5c5-cd1f7da75340: !Template
    answer_choices: null
    id: c05b6121-4f46-4088-a5c5-cd1f7da75340
    jinja: 'What is the French translation of the English sentence: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-en-fr-source+target
    reference: GPT 3 paper
  c26db731-296e-405e-8de7-b9b49fce8407: !Template
    answer_choices: null
    id: c26db731-296e-405e-8de7-b9b49fce8407
    jinja: 'Given the following passage: {{translation["en"]}} , a good French translation
      is: ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-en-fr-target
    reference: ''
  c5e6c439-c0b0-4405-ab3d-22de69b3a82b: !Template
    answer_choices: null
    id: c5e6c439-c0b0-4405-ab3d-22de69b3a82b
    jinja: '{{translation["en"]}} = French:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-en-fr-target
    reference: XGLM paper https://arxiv.org/abs/2112.10668
  cf629f0f-cba7-4623-9e98-d972b56b5b5d: !Template
    answer_choices: null
    id: cf629f0f-cba7-4623-9e98-d972b56b5b5d
    jinja: 'Given the following passage:  {{translation["fr"]}} , a good English translation
      is:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-fr-en-target
    reference: ''
  d76db700-1b29-4ad6-aa04-17fece6a15b0: !Template
    answer_choices: null
    id: d76db700-1b29-4ad6-aa04-17fece6a15b0
    jinja: 'French: {{translation["fr"]}} = English:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-fr-en-source+target
    reference: XGLM paper https://arxiv.org/abs/2112.10668
  dba384a3-65d1-41de-96da-325a9e65a137: !Template
    answer_choices: null
    id: dba384a3-65d1-41de-96da-325a9e65a137
    jinja: 'English: {{translation["en"]}} = French:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-en-fr-source-target
    reference: Adapted from XGLM paper on few shot evaluation https://arxiv.org/abs/2112.10668
  e24ed618-f906-48d3-b9d0-9dd6c2864905: !Template
    answer_choices: null
    id: e24ed618-f906-48d3-b9d0-9dd6c2864905
    jinja: '{{translation["fr"]}} = English:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-fr-en-target
    reference: XGLM paper https://arxiv.org/abs/2112.10668
  e971a8d9-b190-4c99-95fc-f0db73d99928: !Template
    answer_choices: null
    id: e971a8d9-b190-4c99-95fc-f0db73d99928
    jinja: 'If the original version says: {{translation["fr"]}}; then the English
      version should say:

      |||   {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-fr-en-target
    reference: ''
  f341ebe5-3f02-477b-bbc1-33a1d0750062: !Template
    answer_choices: null
    id: f341ebe5-3f02-477b-bbc1-33a1d0750062
    jinja: ' {{translation["en"]}}  translates into French as:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_en-fr-target
    reference: ''
  f7e45e6b-e002-4cdf-a0f2-40b38f678697: !Template
    answer_choices: null
    id: f7e45e6b-e002-4cdf-a0f2-40b38f678697
    jinja: 'How do you say {{translation["fr"]}} in English?

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: how_to_say-fr-en-target
    reference: ''
  f960ea4e-fd15-4c7d-baf5-139ccd5ca6b3: !Template
    answer_choices: null
    id: f960ea4e-fd15-4c7d-baf5-139ccd5ca6b3
    jinja: 'Given the following source text in French: {{translation["fr"]}} , a good
      English translation is: ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-fr-en-source+target
    reference: ''
