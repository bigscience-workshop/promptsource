dataset: super_glue
subset: copa
templates:
  150789fe-e309-47a1-82c9-0a4dc2c6b12b: !Template
    answer_choices: null
    answer_choices_key: '{{choice1}} ||| {{choice2}}'
    id: 150789fe-e309-47a1-82c9-0a4dc2c6b12b
    jinja: "{% if question == \"effect\" %} \n{{ premise }} What could happen next,\
      \ \"{{ answer_choices[0] }}\" or \"{{ answer_choices[1] }}\"? ||| {{ answer_choices[label]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: true
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026What could happen next, C1 or C2?"
    reference: ''
  744047dc-1298-45a2-8d68-d67e3f834ded: !Template
    answer_choices: null
    answer_choices_key: '{{choice1 }} ||| {{choice2}}'
    id: 744047dc-1298-45a2-8d68-d67e3f834ded
    jinja: '"{{ answer_choices[0] }}" or "{{ answer_choices[1] }}"? {{ premise }}
      {% if question == "cause" %} because {% else %} so {% endif %} ||| {{ answer_choices[label]
      }}'
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: true
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "C1 or C2? premise, so/because\u2026"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  84da62c2-9440-4cfc-bdd4-d70c65e33a82: !Template
    answer_choices: null
    answer_choices_key: '{{choice1}} ||| {{choice2}}'
    id: 84da62c2-9440-4cfc-bdd4-d70c65e33a82
    jinja: "{% if question == \"effect\" %} \n{{ premise }} As a result, \"{{ answer_choices[0]\
      \ }}\" or \"{{ answer_choices[1] }}\"? ||| {{ answer_choices[label] }}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: true
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026As a result, C1 or C2?"
    reference: ''
  8cf2ba73-aee5-4651-b5d4-b1b88afe4abb: !Template
    answer_choices: null
    answer_choices_key: '{{choice1}} ||| {{choice2}}'
    id: 8cf2ba73-aee5-4651-b5d4-b1b88afe4abb
    jinja: "{% if question == \"cause\" %} \n{{ premise }} Which may be caused by\
      \ \"{{ answer_choices[0] }}\" or \"{{ answer_choices[1] }}\"? ||| {{ answer_choices[label]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: true
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026which may be caused by"
    reference: ''
  a8bf11c3-bea2-45ba-a533-957d8bee5e2e: !Template
    answer_choices: null
    answer_choices_key: '{{choice1}} ||| {{choice2}}'
    id: a8bf11c3-bea2-45ba-a533-957d8bee5e2e
    jinja: "{% if question == \"cause\" %} \n{{ premise }} Why? \"{{ answer_choices[0]\
      \ }}\" or \"{{ answer_choices[1] }}\"? ||| {{ answer_choices[label] }}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: true
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026why? C1 or C2"
    reference: ''
  f794f8d0-e81b-4ba9-bc3d-dc8201c38954: !Template
    answer_choices: null
    answer_choices_key: '{{choice1}} ||| {{choice2}}'
    id: f794f8d0-e81b-4ba9-bc3d-dc8201c38954
    jinja: "{% if question == \"effect\" %} \n{{ premise }} Which may cause \"{{ answer_choices[0]\
      \ }}\" or \"{{ answer_choices[1] }}\"? ||| {{ answer_choices[label] }}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      _do_eval: true
      _do_train: true
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026which may cause C1 or C2?"
    reference: ''
