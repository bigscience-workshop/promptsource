dataset: super_glue
subset: copa
templates:
  150789fe-e309-47a1-82c9-0a4dc2c6b12b: !Template
    answer_choices: null
    id: 150789fe-e309-47a1-82c9-0a4dc2c6b12b
    jinja: "{% if question == \"effect\" %} \n{{ premise }} What could happen next,\
      \ \"{{ choice1 }}\" or \"{{ choice2 }}\"? ||| {{ [choice1, choice2][label] }}\n\
      {% endif %}"
    metadata: !TemplateMetadata
      answer_span_indices: null
      counting: null
      long_distance: null
      negated_answers: null
      no_sep_2_sentences: null
      non_natural_language: null
      nontrivial_choices_given: null
      nontrivial_choices_hidden: null
      task_template: true
      trivial_choices_given: null
      trivial_choices_hidden: null
    name: "\u2026What could happen next, C1 or C2?"
    reference: ''
  744047dc-1298-45a2-8d68-d67e3f834ded: !Template
    answer_choices: null
    id: 744047dc-1298-45a2-8d68-d67e3f834ded
    jinja: '"{{ choice1 }}" or "{{ choice2 }}"? {{ premise }} {% if question == "cause"
      %} because {% else %} so {% endif %} ||| {{ [choice1, choice2][label] }}'
    metadata: !TemplateMetadata
      answer_span_indices: null
      counting: null
      long_distance: null
      negated_answers: null
      no_sep_2_sentences: null
      non_natural_language: null
      nontrivial_choices_given: null
      nontrivial_choices_hidden: null
      task_template: true
      trivial_choices_given: null
      trivial_choices_hidden: null
    name: "C1 or C2? premise, so/because\u2026"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  84da62c2-9440-4cfc-bdd4-d70c65e33a82: !Template
    answer_choices: null
    id: 84da62c2-9440-4cfc-bdd4-d70c65e33a82
    jinja: "{% if question == \"effect\" %} \n{{ premise }} As a result, \"{{ choice1\
      \ }}\" or \"{{ choice2 }}\"? ||| {{ [choice1, choice2][label] }}\n{% endif %}"
    metadata: !TemplateMetadata
      answer_span_indices: null
      counting: null
      long_distance: null
      negated_answers: null
      no_sep_2_sentences: null
      non_natural_language: null
      nontrivial_choices_given: null
      nontrivial_choices_hidden: null
      task_template: true
      trivial_choices_given: null
      trivial_choices_hidden: null
    name: "\u2026As a result, C1 or C2?"
    reference: ''
  8cf2ba73-aee5-4651-b5d4-b1b88afe4abb: !Template
    answer_choices: null
    id: 8cf2ba73-aee5-4651-b5d4-b1b88afe4abb
    jinja: "{% if question == \"cause\" %} \n{{ premise }} Which may be caused by\
      \ \"{{ choice1 }}\" or \"{{ choice2 }}\"? ||| {{ [choice1, choice2][label] }}\n\
      {% endif %}"
    metadata: !TemplateMetadata
      answer_span_indices: null
      counting: null
      long_distance: null
      negated_answers: null
      no_sep_2_sentences: null
      non_natural_language: null
      nontrivial_choices_given: null
      nontrivial_choices_hidden: null
      task_template: true
      trivial_choices_given: null
      trivial_choices_hidden: null
    name: "\u2026which may be caused by"
    reference: ''
  a8bf11c3-bea2-45ba-a533-957d8bee5e2e: !Template
    answer_choices: null
    id: a8bf11c3-bea2-45ba-a533-957d8bee5e2e
    jinja: "{% if question == \"cause\" %} \n{{ premise }} Why? \"{{ choice1 }}\"\
      \ or \"{{ choice2 }}\"? ||| {{ [choice1, choice2][label] }}\n{% endif %}"
    metadata: !TemplateMetadata
      answer_span_indices: null
      counting: null
      long_distance: null
      negated_answers: null
      no_sep_2_sentences: null
      non_natural_language: null
      nontrivial_choices_given: null
      nontrivial_choices_hidden: null
      task_template: true
      trivial_choices_given: null
      trivial_choices_hidden: null
    name: "\u2026why? C1 or C2"
    reference: ''
  f794f8d0-e81b-4ba9-bc3d-dc8201c38954: !Template
    answer_choices: null
    id: f794f8d0-e81b-4ba9-bc3d-dc8201c38954
    jinja: "{% if question == \"effect\" %} \n{{ premise }} Which may cause \"{{ choice1\
      \ }}\" or \"{{ choice2 }}\"? ||| {{ [choice1, choice2][label] }}\n{% endif %}"
    metadata: !TemplateMetadata
      answer_span_indices: null
      counting: null
      long_distance: null
      negated_answers: null
      no_sep_2_sentences: null
      non_natural_language: null
      nontrivial_choices_given: null
      nontrivial_choices_hidden: null
      task_template: true
      trivial_choices_given: null
      trivial_choices_hidden: null
    name: "\u2026which may cause C1 or C2?"
    reference: ''
