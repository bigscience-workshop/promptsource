dataset: clue
subset: c3
templates:
  51b3c3fe-2fa2-474a-81f9-5b421c884109: !Template
    answer_choices: '{{ choice | join(" ||| ") }}'
    id: 51b3c3fe-2fa2-474a-81f9-5b421c884109
    jinja: "{% for statement in context %} \n{{ statement }}\n{% endfor %}\nGiven\
      \ the dialogue / passage above, use the following options to answer the question\
      \ \"{{question}}\".\nOptions: \n- {{ answer_choices | join('\\n- ') }}\n|||\n\
      {{ answer }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - zh
      metrics:
      - Accuracy
      original_task: true
    name: answer-question-affirmative
    reference: ''
  5e06f05f-d7dd-4329-b6d8-3a62dcdba838: !Template
    answer_choices: '{{ choice | join(" ||| ") }}'
    id: 5e06f05f-d7dd-4329-b6d8-3a62dcdba838
    jinja: "Question: \"{{question}}\"\nAnswer choices: {{ answer_choices[:-1] | join(',\
      \ ') }}, or  {{ answer_choices[-1] }}?\nPassage: {% for statement in context\
      \ %} \n{{ statement }}\n{% endfor %}\n|||\n{{ answer }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - zh
      metrics:
      - Accuracy
      original_task: true
    name: question_choices_context
    reference: ''
  63b5e5df-40d3-47ee-b77e-bf385c042fa9: !Template
    answer_choices: null
    id: 63b5e5df-40d3-47ee-b77e-bf385c042fa9
    jinja: "Passage: {% for statement in context %} \n{{ statement }}\n{% endfor %}\n\
      What kind of question would elicit an answer response of {{ answer }}?\n|||\n\
      {{ question }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - zh
      metrics:
      - ROUGE
      original_task: false
    name: generate_question
    reference: ''
  a5820d05-a8df-4e31-a284-6969e478174b: !Template
    answer_choices: '{{ choice | join('' ||| '') }}'
    id: a5820d05-a8df-4e31-a284-6969e478174b
    jinja: "Given the dialogue / passage below, what is the answer for the question\
      \ \"{{question}}\"\nAnswer choices: {{ answer_choices[:-1] | join(', ') }},\
      \ or  {{ answer_choices[-1] }}?\n{% for statement in context %} \n{{ statement\
      \ }}\n{% endfor %}\n|||\n{{ answer }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - zh
      metrics:
      - Accuracy
      original_task: true
    name: answer-question-interrogative
    reference: ''
