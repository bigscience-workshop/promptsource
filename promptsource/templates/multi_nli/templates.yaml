dataset: multi_nli
templates:
  4100d721-b9c1-41ef-9392-3eeb64e8a4cd: !Template
    id: 4100d721-b9c1-41ef-9392-3eeb64e8a4cd
    jinja: Given that {{premise}}, it {{"must be true, might be true, or must be false"}}
      that {{hypothesis}}? ||| It {{ ["must be true", "might be true", "must be false"][label]
      }}.
    name: "given\u2026 it must be true that\u2026"
    reference: 'Maybe a little verbose for a generative model, but anecdotally this
      is the most natural way of how I say an NLI sentence pair out loud to humans.
      Caveat: NLI annotations are not meant to be strictly truth-conditional entailment,
      so "must" is not ideal.'
    task_template: true
  6c6d824a-89c8-48cc-a4b5-cab04d649117: !Template
    id: 6c6d824a-89c8-48cc-a4b5-cab04d649117
    jinja: '{{premise}}

      Question: {{hypothesis}} True, False, or Neither? ||| {{ ["True", "Neither",
      "False"][label] }}'
    name: GPT-3 style
    reference: 'Same as reported in Figure G7 of the GPT-3 paper, except that there
      is no task identifying tokens like "anli R1: ".'
    task_template: true
  b2dcedb3-265e-4dfa-bbd2-9d9d992bd389: !Template
    id: b2dcedb3-265e-4dfa-bbd2-9d9d992bd389
    jinja: Given that {{premise}} Does it follow that {{hypothesis}} Yes, no, or maybe?
      ||| {{ ["Yes", "Maybe", "No"][label] }}
    name: "given\u2026 does it follow that\u2026 "
    reference: "\"Does it follow that\" could be replaced with \"can we infer that\u2026\
      \ \", \"is it guaranteed that\u2026\", etc. Ideally there should be a question\
      \ mark after \"does it follow that {hypothesis}?\", but the hypothesis string\
      \ often comes with ending punctuations of its own."
    task_template: true
  ca5a9209-47ed-4ca9-9b03-7ea909f61d96: !Template
    id: ca5a9209-47ed-4ca9-9b03-7ea909f61d96
    jinja: "Sentence 1: {{premise}}\nSentence 2: {{hypothesis}}\nQuestion: Does Sentence\
      \ 1 contradict Sentence 2? Yes, No, or Neutral? |||\n{% if label == 0 %} \n\
      No\n{% elif label == 1 %}\nNeutral\n{% else %}\nYes\n{% endif %}"
    name: does S1 contradict S2?
    reference: Copied from Victor's prompts for XNLI.
    task_template: false
  d067f960-75d9-4fed-bf54-6ddaff123a57: !Template
    id: d067f960-75d9-4fed-bf54-6ddaff123a57
    jinja: "Sentence 1: {{premise}}\nSentence 2: {{hypothesis}}\nQuestion: Does Sentence\
      \ 1 entail Sentence 2? Yes, No, or Neutral? |||\n{% if label == 0 %} \nYes\n\
      {% elif label == 1 %}\nNeutral\n{% else %}\nNo\n{% endif %}"
    name: does S1 entail S2?
    reference: Copied from Victor's prompts for XNLI.
    task_template: true
  f1a17d8b-78fb-4300-bc13-8c4572a091fa: !Template
    id: f1a17d8b-78fb-4300-bc13-8c4572a091fa
    jinja: '{{premise}} Based on the previous passage, is it true that {{hypothesis}}
      Yes, no, or maybe? ||| {{ ["Yes", "Maybe", "No"][label] }}'
    name: based on the previous passage
    reference: "Adapted from the BoolQ prompts in Schick & Sch\xFCtze 2021."
    task_template: true
