dataset: qed
templates:
  292db39d-b9e9-4113-b59d-6c5b93133563: !Template
    answer_choices: null
    id: 292db39d-b9e9-4113-b59d-6c5b93133563
    jinja: "Give a suitable title to the following passage:\n\n{{paragraph_text}}\
      \ \n|||\n\n{{title_text}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: title-prediction
    reference: ''
  3578c1ee-8872-406f-be9f-b7e174aed92c: !Template
    answer_choices: null
    id: 3578c1ee-8872-406f-be9f-b7e174aed92c
    jinja: '{% set chosen = original_nq_answers | choice %}

      Question: {{question}} ?

      |||

      {{ chosen["string"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: true
    name: original-nq-answers
    reference: ''
  383d06fe-d562-4883-8d29-b727d4c3877b: !Template
    answer_choices: null
    id: 383d06fe-d562-4883-8d29-b727d4c3877b
    jinja: "{% if annotation['selected_sentence']['string']!=\"\" %}\nAnswer the following\
      \ question given the hint.\n\nQuestion: {{question}}?\n\nHint: {{paragraph_text}}\
      \  \n\n|||\n{{annotation['selected_sentence']['string']}}\n{% endif %}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: true
    name: qusetion-and-passage-to-answer
    reference: ''
  4cc7af61-ee7a-491f-b232-8ef3dc7d1415: !Template
    answer_choices: No ||| Yes
    id: 4cc7af61-ee7a-491f-b232-8ef3dc7d1415
    jinja: '{% set does_contain = None %}

      {% if annotation["explanation_type"] != "none" %}

      {% set does_contain = 1 %}

      {% else %}

      {% set does_contain = 0 %}

      {% endif %}

      {{paragraph_text}}


      Does the above passage contain the answer to the following question? Please
      answer Yes or No.


      Question: {{question}}?

      |||

      {{answer_choices[does_contain] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: does-explanation-exist
    reference: ''
  5b45c11d-bbea-45a1-a799-a77a56fe8e1d: !Template
    answer_choices: null
    id: 5b45c11d-bbea-45a1-a799-a77a56fe8e1d
    jinja: 'Please extract the title from the given URL (Uniform Resource Locator).


      URL: {{ url }}

      |||

      {{ title_text }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: extract-title-from-url
    reference: ''
  6679de40-be84-43e5-aa0b-2bdb4bdde83d: !Template
    answer_choices: one ||| more than one ||| zero
    id: 6679de40-be84-43e5-aa0b-2bdb4bdde83d
    jinja: '{% set exp_type = None %}

      {% if annotation["explanation_type"] == "single_sentence" %}

      {% set exp_type = 0 %}

      {% elif annotation["explanation_type"] == "multi_sentence" %}

      {% set exp_type = 1 %}

      {% else %}

      {% set exp_type = 2 %}

      {% endif %}


      Read the below paragraph and question A, and answer question B.


      Paragraph: {{paragraph_text}}


      Question A: {{question}}?


      Question B: In order to answer question A, how many sentences did you have to
      reason over in the paragraph? Please answer "one", "more than one", or "zero".

      |||

      {{answer_choices[exp_type]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: explanation-type
    reference: ''
  7d3746b5-52e6-4ce1-b441-007f271f477b: !Template
    answer_choices: null
    id: 7d3746b5-52e6-4ce1-b441-007f271f477b
    jinja: "I need to prepare for my upcoming test. Can you read the below passage\
      \ and ask me a reasonable question? \n\n{{paragraph_text}} \n||| \n\n{{question}}?"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: question-forming
    reference: ''
  86cffd6d-db04-4daf-ab30-f462fd1177e3: !Template
    answer_choices: null
    id: 86cffd6d-db04-4daf-ab30-f462fd1177e3
    jinja: '{% if annotation["selected_sentence"]["string"]  != "" %}

      Read the following paragraph and question A, and answer question B:


      Paragraph: {{ paragraph_text }}


      Question A: {{ question }}?


      Question B: What''s the most important sentence in Paragraph, in order to answer
      question A?

      |||

      {{ annotation["selected_sentence"]["string"] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - Squad
      original_task: true
    name: select-sentence
    reference: ''
