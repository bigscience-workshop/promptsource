dataset: wmt14
subset: fr-en
templates:
  08ddea55-1710-4615-bbfa-fe5803e21e43: !Template
    answer_choices: null
    id: 08ddea55-1710-4615-bbfa-fe5803e21e43
    jinja: 'If the French version says: {{translation["fr"]}}; then the English version
      should say:

      |||   {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-fr-en-source+target
    reference: ''
  0bc0e46c-d1fe-4bc9-99d1-9b61aa42cd02: !Template
    answer_choices: null
    id: 0bc0e46c-d1fe-4bc9-99d1-9b61aa42cd02
    jinja: 'If the English version says: {{translation["en"]}}; then the French version
      should say:

      |||   {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-en-fr-source+target
    reference: ''
  1fbf99d9-980a-4bf8-b30e-dcf9e3ad5feb: !Template
    answer_choices: null
    id: 1fbf99d9-980a-4bf8-b30e-dcf9e3ad5feb
    jinja: 'Translate this from French into English: {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-fr-en-source+target
    reference: https://arxiv.org/pdf/1910.10683.pdf
  2033cc05-3ef7-4c93-9684-90a618390f4b: !Template
    answer_choices: null
    id: 2033cc05-3ef7-4c93-9684-90a618390f4b
    jinja: 'What is the English translation of the French  sentence: {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-fr-en-source+target
    reference: GPT-3 paper
  280bc983-9f20-4e80-ab02-5f333df90a42: !Template
    answer_choices: null
    id: 280bc983-9f20-4e80-ab02-5f333df90a42
    jinja: 'What is the English translation of : {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-fr-en-target
    reference: GPT-3 paper
  2fc841fb-b872-4cc6-9a88-735d6bb7e2e3: !Template
    answer_choices: null
    id: 2fc841fb-b872-4cc6-9a88-735d6bb7e2e3
    jinja: '{{translation["en"]}} = French:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-en-fr-target
    reference: XGLM paper https://arxiv.org/abs/2112.10668
  41e7647e-2b9f-4d86-8987-5abe70000362: !Template
    answer_choices: null
    id: 41e7647e-2b9f-4d86-8987-5abe70000362
    jinja: 'Translate this into English: {{translation["fr"]}}

      |||  {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-fr-en-target
    reference: ''
  43dc1b77-e8ea-4dc8-8a12-0abc3b0dbba0: !Template
    answer_choices: null
    id: 43dc1b77-e8ea-4dc8-8a12-0abc3b0dbba0
    jinja: 'Given the following source text in French: {{translation["fr"]}} , a good
      English translation is: ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-fr-en-source+target
    reference: ''
  474c20a1-a2ea-4ff4-b4c8-7f9c6466ff20: !Template
    answer_choices: null
    id: 474c20a1-a2ea-4ff4-b4c8-7f9c6466ff20
    jinja: 'Given the following passage: {{translation["en"]}} , a good French translation
      is: ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-en-fr-target
    reference: ''
  4933dcae-3a66-4506-a479-a1387b287232: !Template
    answer_choices: null
    id: 4933dcae-3a66-4506-a479-a1387b287232
    jinja: 'What is the French translation of: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-en-fr-target
    reference: GPT-3 paper
  51d41a04-1d90-4bae-b6e5-be7598cdbfb0: !Template
    answer_choices: null
    id: 51d41a04-1d90-4bae-b6e5-be7598cdbfb0
    jinja: 'How do you say {{translation["fr"]}} in English?

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: how_to_say-fr-en-target
    reference: ''
  527d2074-74fa-47ec-802e-7373728230df: !Template
    answer_choices: null
    id: 527d2074-74fa-47ec-802e-7373728230df
    jinja: 'Translate this into French: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-en-fr-target
    reference: ''
  5af8c873-7176-46b8-a31a-2b2d393c6c68: !Template
    answer_choices: null
    id: 5af8c873-7176-46b8-a31a-2b2d393c6c68
    jinja: 'Translate this from English into French: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate-en-fr-source+starget
    reference: ''
  762c0878-c8fc-43ec-839f-d5d8435a94f6: !Template
    answer_choices: null
    id: 762c0878-c8fc-43ec-839f-d5d8435a94f6
    jinja: 'Given the following passage:  {{translation["fr"]}} , a good English translation
      is:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-fr-en-target
    reference: ''
  8713594d-626b-4c5c-a63f-553ddc5444de: !Template
    answer_choices: null
    id: 8713594d-626b-4c5c-a63f-553ddc5444de
    jinja: 'English: {{translation["en"]}} = French:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-en-fr-source-target
    reference: Adapted from XGLM paper on few shot evaluation https://arxiv.org/abs/2112.10668
  957b8554-a00a-4652-b080-e9ee3ccae381: !Template
    answer_choices: null
    id: 957b8554-a00a-4652-b080-e9ee3ccae381
    jinja: '{{translation["fr"]}} = English:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-fr-en-target
    reference: XGLM paper https://arxiv.org/abs/2112.10668
  9fe6b44b-2dc6-4557-8201-14d6ea7668ff: !Template
    answer_choices: null
    id: 9fe6b44b-2dc6-4557-8201-14d6ea7668ff
    jinja: 'If the original version says: {{translation["fr"]}}; then the English
      version should say:

      |||   {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-fr-en-target
    reference: ''
  a3a87505-e423-4c03-9a22-a3da4ccbeae5: !Template
    answer_choices: null
    id: a3a87505-e423-4c03-9a22-a3da4ccbeae5
    jinja: 'Given the following source text in English: {{translation["en"]}} , a
      good French translation is:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: a_good_translation-en-fr-source+target
    reference: ''
  a7fc5e89-884d-4bc5-ba8a-b500dfbd3453: !Template
    answer_choices: null
    id: a7fc5e89-884d-4bc5-ba8a-b500dfbd3453
    jinja: ' {{translation["en"]}}  translates into French as:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_en-fr-target
    reference: ''
  aad799b1-defb-44a9-bd51-1abcaa29fad7: !Template
    answer_choices: null
    id: aad799b1-defb-44a9-bd51-1abcaa29fad7
    jinja: 'English:  {{translation["en"]}}  translates into French as:

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_en-fr-source+target
    reference: ''
  b0e110eb-4fde-45fd-a561-e8e24ad83916: !Template
    answer_choices: null
    id: b0e110eb-4fde-45fd-a561-e8e24ad83916
    jinja: 'French: {{translation["fr"]}} = English:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: xglm-fr-en-source+target
    reference: XGLM paper https://arxiv.org/abs/2112.10668
  bc95c647-5979-4522-9e6e-f5eb93b69a00: !Template
    answer_choices: null
    id: bc95c647-5979-4522-9e6e-f5eb93b69a00
    jinja: 'French:  {{translation["fr"]}}  translates into English as:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_fr-en-source+target
    reference: ''
  c50ca84e-3ca7-4c3c-89e1-3c95351f6ed8: !Template
    answer_choices: null
    id: c50ca84e-3ca7-4c3c-89e1-3c95351f6ed8
    jinja: 'How do you say {{translation["en"]}} in French?

      ||| {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: how_to_say-en-fr-target
    reference: ''
  c80e443a-0ba4-4c5d-be98-998e050a202d: !Template
    answer_choices: null
    id: c80e443a-0ba4-4c5d-be98-998e050a202d
    jinja: 'If the original version says: {{translation["en"]}}; then the French version
      should say:

      |||   {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: version-en-fr-target
    reference: ''
  dd003b93-943e-41c9-8454-23f647e77dcc: !Template
    answer_choices: null
    id: dd003b93-943e-41c9-8454-23f647e77dcc
    jinja: '{{translation["fr"]}}  translates into English as:

      ||| {{translation["en"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: translate_as_fr-en-target
    reference: ''
  ec3b96b0-de5e-4ff4-b7bb-cda348ff7fcf: !Template
    answer_choices: null
    id: ec3b96b0-de5e-4ff4-b7bb-cda348ff7fcf
    jinja: 'What is the French translation of the English sentence: {{translation["en"]}}

      |||  {{translation["fr"]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages: []
      metrics:
      - BLEU
      original_task: true
    name: gpt-3-en-fr-source+target
    reference: GPT 3 paper
