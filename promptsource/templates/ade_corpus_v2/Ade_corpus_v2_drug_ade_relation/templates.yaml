dataset: ade_corpus_v2
subset: Ade_corpus_v2_drug_ade_relation
templates:
  0ec35408-652d-4ebc-9478-5a0d330c24c8: !Template
    answer_choices: null
    id: 0ec35408-652d-4ebc-9478-5a0d330c24c8
    jinja: 'What drug has an effect of {{effect}}?

      |||

      {{drug}}'
    metadata: !TemplateMetadata
      choices_in_prompt: null
      metrics: []
      original_task: null
    name: effect2drug
    reference: ''
  2682a789-a435-4976-b34f-f376991c842a: !Template
    answer_choices: null
    id: 2682a789-a435-4976-b34f-f376991c842a
    jinja: '{{drug}} has an effect of {{effect}}. Create a sentence using this drug
      and its effect.

      |||

      {{text}}'
    metadata: !TemplateMetadata
      choices_in_prompt: null
      metrics: []
      original_task: null
    name: drug-and-effect-to-text
    reference: ''
  61ba3622-72bc-4fd8-acfc-826bc2a93aa5: !Template
    answer_choices: null
    id: 61ba3622-72bc-4fd8-acfc-826bc2a93aa5
    jinja: 'What effect does {{drug}} have?

      |||

      {{effect}}'
    metadata: !TemplateMetadata
      choices_in_prompt: null
      metrics: []
      original_task: null
    name: drug2effect
    reference: ''
  6acf3588-baa1-4ff6-87c4-4c2356855464: !Template
    answer_choices: null
    id: 6acf3588-baa1-4ff6-87c4-4c2356855464
    jinja: 'Read the below text and answer the question.


      Text: {{text}}


      Question: What are the drug and its effect of the above text, respectively?

      |||

      {{drug}} and {{effect}}, respectively.'
    metadata: !TemplateMetadata
      choices_in_prompt: null
      metrics: []
      original_task: true
    name: baseline
    reference: ''
  db68e609-ba92-40ae-b161-8b7710124142: !Template
    answer_choices: null
    id: db68e609-ba92-40ae-b161-8b7710124142
    jinja: 'Read the below text and answer the two following questions.


      Text: {{text}}


      Question 1: What is the drug in the above text?


      Question 2: What is the effect of it?

      |||

      The drug is {{drug}} and its effect is {{effect}}.'
    metadata: !TemplateMetadata
      choices_in_prompt: null
      metrics: []
      original_task: null
    name: two-questions
    reference: ''
