# coding=utf-8

# Hard-coded additional English datasets
# These datasets have either metadata missing or language informations missing
# so we manually identified them.
_ADDITIONAL_ENGLISH_DATSETS = [
    "aeslc",
    "ai2_arc",
    "amazon_us_reviews",
    "anli",
    "art",
    "aslg_pc12",
    "asnq",
    "biomrc",
    "blended_skill_talk",
    "blimp",
    "blog_authorship_corpus",
    "bookcorpus",
    "bookcorpusopen",
    "boolq",
    "break_data",
    "cfq",
    "civil_comments",
    "com_qa",
    "common_gen",
    "commonsense_qa",
    "conll2000",
    "coqa",
    "cornell_movie_dialog",
    "cos_e",
    "cosmos_qa",
    "crd3",
    "crime_and_punish",
    "daily_dialog",
    "definite_pronoun_resolution",
    "discofuse",
    "docred",
    "doqa",
    "drop",
    "emo",
    "emotion",
    "empathetic_dialogues",
    "eraser_multi_rc",
    "esnli",
    "event2Mind",
    "fever",
    "gap",
    "gigaword",
    "guardian_authorship",
    "hans",
    "hellaswag",
    "hotpot_qa",
    "hyperpartisan_news_detection",
    "imdb",
    "jeopardy",
    "lc_quad",
    "math_dataset",
    "math_qa",
    "mlqa",
    "movie_rationales",
    "ms_marco",
    "multi_news",
    "mwsc",
    "natural_questions",
    "newsgroup",
    "newsroom",
    "openbookqa",
    "openwebtext",
    "opinosis",
    "pg19",
    "qa_zre",
    "qangaroo",
    "qanta",
    "qasc",
    "quail",
    "quarel",
    "quartz",
    "quora",
    "quoref",
    "race",
    "reddit",
    "reddit_tifu",
    "reuters21578",
    "rotten_tomatoes",
    "scan",
    "scicite",
    "scientific_papers",
    "scifact",
    "sciq",
    "scitail",
    "search_qa",
    "sem_eval_2010_task_8",
    "sentiment140",
    "social_i_qa",
    "squad_v2",
    "squadshifts",
    "super_glue",
    "trec",
    "trivia_qa",
    "tydiqa",
    "ubuntu_dialogs_corpus",
    "web_nlg",
    "web_of_science",
    "web_questions",
    "wiki40b",
    "wiki_qa",
    "wiki_snippets",
    "wiki_split",
    "wikipedia",
    "wikisql",
    "wikitext",
    "winogrande",
    "wiqa",
    "wnut_17",
    "xnli",
    "xquad",
    "xsum",
    "xtreme",
    "yelp_polarity"
]

def removeHyphen(example):
    example_clean = {}
    for key in example.keys():
        if "-" in key:
           new_key = key.replace("-","_")
           example_clean[new_key] = example[key]
        else:
           example_clean[key] = example[key]
    example = example_clean
    return example
 
